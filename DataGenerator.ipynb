{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a08b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1247d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, db_dir, batch_size, input_shape, num_classes, \n",
    "                 shuffle=True, dir_classes=False):\n",
    "        \n",
    "        self.current_counter = 0\n",
    "        self.label_dict = {}\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # load the data from the root directory\n",
    "        self.data, self.labels = self.get_data(db_dir)\n",
    "        self.indices = np.arange(len(self.data))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def get_data(self, root_dir):\n",
    "        \"\"\"\"\n",
    "        Loads the paths to the images and their corresponding labels from the database directory\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        path = self.db_dir\n",
    "\n",
    "        for l in os.listdir(path):\n",
    "          \n",
    "          \n",
    "        \n",
    "          cd = None\n",
    "          try:\n",
    "            cd = Image.open(path + '/' + l)\n",
    "            cd = np.asarray(cd)\n",
    "          except:\n",
    "            continue\n",
    "\n",
    "          #self.data.append(path+'/'+l)\n",
    "          #self.labels.append(1 if str(l[0]).islower() else 0)\n",
    "          l_class = \"\".join(l.split('_')[:-1])\n",
    "          if l_class not in self.label_dict.keys():\n",
    "            self.label_dict[l_class] = self.current_counter\n",
    "            self.current_counter += 1\n",
    "          #self.labels\n",
    "        \n",
    "        \"\"\"\n",
    "            Second loop.\n",
    "        \"\"\"\n",
    "        for l in os.listdir(path):\n",
    "          cd = None\n",
    "          try:\n",
    "            cd = Image.open(path + '/' + l)\n",
    "            cd = np.asarray(cd)\n",
    "          except:\n",
    "            continue\n",
    "\n",
    "          self.data.append(path+'/'+l)\n",
    "          l_class = \"\".join(l.split('_')[:-1])\n",
    "#           self.labels.append(self.label_dict[l_class])\n",
    "          self.labels.append(0 if l[0].islower() else 1)\n",
    "    \n",
    "        return self.data, self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of batches per epoch: the total size of the dataset divided by the batch size\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "        # TODO your code  here (size of dataset divided by the batch size)\n",
    "        return 0\n",
    "    \n",
    "    def vec_to_tensor(self, v):\n",
    "      return constant(v)\n",
    "    \n",
    "    \"\"\"\n",
    "        Preprocesses before outputting to .fit()\n",
    "        This can mean: reshape, channel count check, mean subtraction and std. dev division.\n",
    "    \"\"\"\n",
    "    def batch_to_train(self, batch_x, batch_y):\n",
    "        x_train = [self.vec_to_tensor(x) for x in batch_x]\n",
    "        y_train = [self.vec_to_tensor(x) for x in batch_y]\n",
    "\n",
    "        #print(self.input_shape)\n",
    "        x_train = [cv2.resize(np.array(i), (self.input_shape[0], self.input_shape[1])) for i in x_train]\n",
    "        x_train2 = []\n",
    "        y_train2 = []\n",
    "\n",
    "        for i in range(len(x_train)):\n",
    "          if (x_train[i].shape[0] == self.input_shape[0] and x_train[i].shape[1] == self.input_shape[1] and x_train[i].shape[2] == 3):\n",
    "            x_train2.append(x_train[i])\n",
    "            y_train2.append([y_train[i].numpy(), 0 if y_train[i].numpy() == 1 else 1])\n",
    "\n",
    "        y_test = y_train2[:floor(1/5 * self.batch_size)]\n",
    "        x_test = x_train2[:floor(1/5 * self.batch_size)]\n",
    "\n",
    "        x_train = x_train2[ceil(1/5 * self.batch_size + 1):]\n",
    "        y_train = y_train2[ceil(1/5 * self.batch_size + 1):]\n",
    "\n",
    "        \n",
    "        \n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        \n",
    "#         mean = x_train.mean(axis=(0, 1, 2))\n",
    "#         x_train[..., 0] = x_train[..., 0] - mean[0]\n",
    "#         x_train[..., 1] = x_train[..., 1] - mean[1]\n",
    "#         x_train[..., 2] = x_train[..., 2] - mean[2]\n",
    "        \n",
    "        x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "            \n",
    "        return x_train, y_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\"\n",
    "        Generates a batch of data\n",
    "        Note: computation intensivity\n",
    "        \"\"\"\n",
    "\n",
    "        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        \n",
    "        batch_x = [] # TODO load the image(s) from batch_indices\n",
    "        batch_y = [] # TODO load the corresponding labels of the images you loaded\n",
    "\n",
    "        for i in batch_indices:\n",
    "          ci = self.data[i]\n",
    "          cl = self.labels[i]\n",
    "            \n",
    "          cd = Image.open(ci)\n",
    "          cd = np.asarray(cd)\n",
    "\n",
    "          if (len(cd.shape) != 3):\n",
    "            continue\n",
    "          # reshape?\n",
    "\n",
    "          batch_x.append(cd)\n",
    "          batch_y.append(cl)\n",
    "        \n",
    "         \n",
    "\n",
    "        # optionally you can use: batch_y = tf.keras.utils.to_categorical(batch_y, num_classes=self.num_classes)\n",
    "        return self.batch_to_train(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\"\n",
    "        Called at the end of each epoch\n",
    "        \"\"\"\n",
    "        # if required, shuffle your data after each epoch\n",
    "        self.indices = np.arange(len(self.data))\n",
    "        if self.shuffle:\n",
    "            # TODO shuffle data\n",
    "            # you might find np.random.shuffle useful here\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataGenerator(\n",
    "    db_dir='./dataset',\n",
    "    batch_size=4,\n",
    "    input_shape=(120, 120),\n",
    "    dir_classes=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
